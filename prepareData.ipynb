{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import geojson\n",
    "import os\n",
    "import json\n",
    "import shutil\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "from shapely.geometry import Point, MultiPolygon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import csv in pandas\n",
    "df = pd.read_csv('ita_general_2020.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   longitude   latitude\n",
      "0   6.215694  48.000139\n",
      "1   6.216250  48.000139\n",
      "2   6.216528  48.000139\n",
      "3   6.243750  48.000139\n",
      "4   6.244028  48.000139\n"
     ]
    }
   ],
   "source": [
    "df = df.drop(columns=['ita_general_2020'])\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   longitude   latitude         x          y\n",
      "0   6.215694  48.000139  0.215833  12.999722\n",
      "1   6.216250  48.000139  0.216389  12.999722\n",
      "2   6.216528  48.000139  0.216667  12.999722\n",
      "3   6.243750  48.000139  0.243889  12.999722\n",
      "4   6.244028  48.000139  0.244167  12.999722\n"
     ]
    }
   ],
   "source": [
    "min_lon = df['longitude'].min()\n",
    "min_lat = df['latitude'].min()\n",
    "\n",
    "df['x'] = df.apply(lambda row: row['longitude'] - min_lon, axis=1)\n",
    "df['y'] = df.apply(lambda row: row['latitude'] - min_lat, axis=1)\n",
    "\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write in csv df\n",
    "df.to_csv('italy_xy.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('region_shape.geojson') as f:\n",
    "    data = json.load(f)\n",
    "    \n",
    "polygons = gpd.GeoDataFrame.from_features(data['features'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_city_dataset(city_name, region = False, region_name = None):\n",
    "    \n",
    "    city = polygons[polygons['prov_name'] == city_name]\n",
    "\n",
    "    city_polygon = city['geometry'].iloc[0]\n",
    "\n",
    "    city_polygon = MultiPolygon(city_polygon)\n",
    "\n",
    "    df['in_city'] = df.apply(lambda row: city_polygon.contains(Point(row['longitude'], row['latitude'])), axis=1)\n",
    "\n",
    "    city_df = df[df['in_city'] == True]\n",
    "\n",
    "    city_df = city_df.drop(['in_city'], axis=1)\n",
    "    city_df = city_df.drop(['ita_general_2020'],axis=1)\n",
    "\n",
    "    city_df['x'] = city_df.apply(lambda row: row['longitude'] - city_df['longitude'].min(), axis=1)\n",
    "    city_df['y'] = city_df.apply(lambda row: row['latitude'] - city_df['latitude'].min(), axis=1)\n",
    "\n",
    "    if(region):\n",
    "        city_df.to_csv(region_name+\"_\"+city_name+'_xy.csv', index=False)\n",
    "    else:\n",
    "        city_df.to_csv(city_name+'_xy.csv', index=False)\n",
    "    \n",
    "\n",
    "def get_region_dataset(region_name):\n",
    "    cities = polygons[polygons['reg_name'] == region_name]['prov_name'].unique()\n",
    "    print(cities)\n",
    "    for city in cities:\n",
    "        get_city_dataset(city, True, region_name)\n",
    "    path = os.getcwd()\n",
    "    files = [f for f in os.listdir(path) if os.path.isfile(os.path.join(path, f))]\n",
    "    files = [f for f in files if f.startswith(region_name)]\n",
    "    print(files)\n",
    "    df = pd.concat([pd.read_csv(f) for f in files])\n",
    "    df.to_csv(region_name+'_xy.csv', index=False)\n",
    "    for f in files:\n",
    "        os.remove(f)\n",
    "    path = os.getcwd()\n",
    "    files = [f for f in os.listdir(path) if os.path.isfile(os.path.join(path, f))]\n",
    "    files = [f for f in files if  f.startswith(region_name) and f.endswith('_xy.csv')]\n",
    "    print(files)\n",
    "    for f in files:\n",
    "        shutil.move(f, './scp_project/src/resources/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_city_dataset('Roma')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_region_dataset('Umbria')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4976e0179d97dd6d59b1329a76e601e17b789c2571b41c8b57f5fd69821c0dd3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
